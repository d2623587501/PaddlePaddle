{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# ① 问题定义\n",
    "\n",
    "十二生肖分类的本质是图像分类任务，我们采用CNN网络结构进行相关实践。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# ② 数据准备\n",
    "\n",
    "## 2.1 解压缩数据集\n",
    "\n",
    "我们将网上获取的数据集以压缩包的方式上传到aistudio数据集中，并加载到我们的项目内。\n",
    "\n",
    "在使用之前我们进行数据集压缩包的一个解压。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!unzip -q -o data/data76110/signs.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 2.2 数据标注\n",
    "\n",
    "我们先看一下解压缩后的数据集长成什么样子。\n",
    "\n",
    "```bash\n",
    ".\n",
    "├── test\n",
    "│   ├── dog\n",
    "│   ├── dragon\n",
    "│   ├── goat\n",
    "│   ├── horse\n",
    "│   ├── monkey\n",
    "│   ├── ox\n",
    "│   ├── pig\n",
    "│   ├── rabbit\n",
    "│   ├── ratt\n",
    "│   ├── rooster\n",
    "│   ├── snake\n",
    "│   └── tiger\n",
    "├── train\n",
    "│   ├── dog\n",
    "│   ├── dragon\n",
    "│   ├── goat\n",
    "│   ├── horse\n",
    "│   ├── monkey\n",
    "│   ├── ox\n",
    "│   ├── pig\n",
    "│   ├── rabbit\n",
    "│   ├── ratt\n",
    "│   ├── rooster\n",
    "│   ├── snake\n",
    "│   └── tiger\n",
    "└── valid\n",
    "    ├── dog\n",
    "    ├── dragon\n",
    "    ├── goat\n",
    "    ├── horse\n",
    "    ├── monkey\n",
    "    ├── ox\n",
    "    ├── pig\n",
    "    ├── rabbit\n",
    "    ├── ratt\n",
    "    ├── rooster\n",
    "    ├── snake\n",
    "    └── tiger\n",
    "```\n",
    "\n",
    "数据集分为train、valid、test三个文件夹，每个文件夹内包含12个分类文件夹，每个分类文件夹内是具体的样本图片。\n",
    "\n",
    "我们对这些样本进行一个标注处理，最终生成train.txt/valid.txt/test.txt三个数据标注文件。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "text = '''__all__ = ['CONFIG', 'get']\r\n",
    "\r\n",
    "CONFIG = {\r\n",
    "    'model_save_dir': \"./output/zodiac\",\r\n",
    "    'num_classes': 12,\r\n",
    "    'total_images': 7096,\r\n",
    "    'epochs': 20,\r\n",
    "    'batch_size': 32,\r\n",
    "    'image_shape': [3, 224, 224],\r\n",
    "    'LEARNING_RATE': {\r\n",
    "        'params': {\r\n",
    "            'lr': 0.00375             \r\n",
    "        }\r\n",
    "    },\r\n",
    "    'OPTIMIZER': {\r\n",
    "        'params': {\r\n",
    "            'momentum': 0.9\r\n",
    "        },\r\n",
    "        'regularizer': {\r\n",
    "            'function': 'L2',\r\n",
    "            'factor': 0.000001\r\n",
    "        }\r\n",
    "    },\r\n",
    "    'LABEL_MAP': [\r\n",
    "        \"ratt\",\r\n",
    "        \"ox\",\r\n",
    "        \"tiger\",\r\n",
    "        \"rabbit\",\r\n",
    "        \"dragon\",\r\n",
    "        \"snake\",\r\n",
    "        \"horse\",\r\n",
    "        \"goat\",\r\n",
    "        \"monkey\",\r\n",
    "        \"rooster\",\r\n",
    "        \"dog\",\r\n",
    "        \"pig\",\r\n",
    "    ]\r\n",
    "}\r\n",
    "\r\n",
    "def get(full_path):\r\n",
    "    for id, name in enumerate(full_path.split('.')):\r\n",
    "        if id == 0:\r\n",
    "            config = CONFIG\r\n",
    "        \r\n",
    "        config = config[name]\r\n",
    "    \r\n",
    "    return config\r\n",
    "'''\r\n",
    "fid = open('config.py', 'w')\r\n",
    "fid.write(text)\r\n",
    "fid.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import io\n",
    "import os\n",
    "from PIL import Image\n",
    "from config import get\n",
    "\n",
    "\n",
    "# 数据集根目录\n",
    "DATA_ROOT = 'signs'\n",
    "\n",
    "# 标签List\n",
    "LABEL_MAP = get('LABEL_MAP')\n",
    "\n",
    "# 标注生成函数\n",
    "def generate_annotation(mode):\n",
    "    # 建立标注文件\n",
    "    with open('{}/{}.txt'.format(DATA_ROOT, mode), 'w') as f:\n",
    "        # 对应每个用途的数据文件夹，train/valid/test\n",
    "        train_dir = '{}/{}'.format(DATA_ROOT, mode)\n",
    "\n",
    "        # 遍历文件夹，获取里面的分类文件夹\n",
    "        for path in os.listdir(train_dir):\n",
    "            # 标签对应的数字索引，实际标注的时候直接使用数字索引\n",
    "            label_index = LABEL_MAP.index(path)\n",
    "\n",
    "            # 图像样本所在的路径\n",
    "            image_path = '{}/{}'.format(train_dir, path)\n",
    "\n",
    "            # 遍历所有图像\n",
    "            for image in os.listdir(image_path):\n",
    "                # 图像完整路径和名称\n",
    "                image_file = '{}/{}'.format(image_path, image)\n",
    "                \n",
    "                try:\n",
    "                    # 验证图片格式是否ok\n",
    "                    with open(image_file, 'rb') as f_img:\n",
    "                        image = Image.open(io.BytesIO(f_img.read()))\n",
    "                        image.load()\n",
    "                        \n",
    "                        if image.mode == 'RGB':\n",
    "                            f.write('{}\\t{}\\n'.format(image_file, label_index))\n",
    "                except:\n",
    "                    continue\n",
    "\n",
    "\n",
    "generate_annotation('train')  # 生成训练集标注文件\n",
    "generate_annotation('valid')  # 生成验证集标注文件\n",
    "generate_annotation('test')   # 生成测试集标注文件"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 2.3 数据集定义\n",
    "\n",
    "接下来我们使用标注好的文件进行数据集类的定义，方便后续模型训练使用。\n",
    "\n",
    "### 2.3.1 导入相关库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.1'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import paddle\n",
    "import numpy as np\n",
    "from config import get\n",
    "\n",
    "paddle.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 2.3.2 导入数据集的定义实现\n",
    "\n",
    "我们数据集的代码实现是在dataset.py中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "text = '''import paddle\r\n",
    "import paddle.vision.transforms as T\r\n",
    "import numpy as np\r\n",
    "from config import get\r\n",
    "from PIL import Image\r\n",
    "\r\n",
    "__all__ = ['ZodiacDataset']\r\n",
    "\r\n",
    "# 定义图像的大小\r\n",
    "image_shape = get('image_shape')\r\n",
    "IMAGE_SIZE = (image_shape[1], image_shape[2])\r\n",
    "\r\n",
    "\r\n",
    "class ZodiacDataset(paddle.io.Dataset):\r\n",
    "    \"\"\"\r\n",
    "    十二生肖数据集类的定义\r\n",
    "    \"\"\"\r\n",
    "\r\n",
    "    def __init__(self, mode='train'):\r\n",
    "        \"\"\"\r\n",
    "        初始化函数\r\n",
    "        \"\"\"\r\n",
    "        assert mode in ['train', 'test', 'valid'], 'mode is one of train, test, valid.'\r\n",
    "\r\n",
    "        self.data = []\r\n",
    "\r\n",
    "        with open('signs/{}.txt'.format(mode)) as f:\r\n",
    "            for line in f.readlines():\r\n",
    "                info = line.strip().split('\\t')\r\n",
    "\r\n",
    "                if len(info) > 0:\r\n",
    "                    self.data.append([info[0].strip(), info[1].strip()])\r\n",
    "\r\n",
    "        if mode == 'train':\r\n",
    "            self.transforms = T.Compose([\r\n",
    "                T.RandomResizedCrop(IMAGE_SIZE),    # 随机裁剪大小\r\n",
    "                T.RandomHorizontalFlip(0.5),        # 随机水平翻转\r\n",
    "                T.ToTensor(),                       # 数据的格式转换和标准化 HWC => CHW  \r\n",
    "                T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # 图像归一化\r\n",
    "            ])\r\n",
    "        else:\r\n",
    "            self.transforms = T.Compose([\r\n",
    "                T.Resize(256),                 # 图像大小修改\r\n",
    "                T.RandomCrop(IMAGE_SIZE),      # 随机裁剪\r\n",
    "                T.ToTensor(),                  # 数据的格式转换和标准化 HWC => CHW\r\n",
    "                T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])   # 图像归一化\r\n",
    "            ])\r\n",
    "        \r\n",
    "    def __getitem__(self, index):\r\n",
    "        \"\"\"\r\n",
    "        根据索引获取单个样本\r\n",
    "        \"\"\"\r\n",
    "        image_file, label = self.data[index]\r\n",
    "        image = Image.open(image_file)\r\n",
    "\r\n",
    "        if image.mode != 'RGB':\r\n",
    "            image = image.convert('RGB')\r\n",
    "\r\n",
    "        image = self.transforms(image)\r\n",
    "\r\n",
    "        return image, np.array(label, dtype='int64')\r\n",
    "\r\n",
    "    def __len__(self):\r\n",
    "        \"\"\"\r\n",
    "        获取样本总数\r\n",
    "        \"\"\"\r\n",
    "        return len(self.data)\r\n",
    "'''\r\n",
    "fid = open('dataset.py', 'w')\r\n",
    "fid.write(text)\r\n",
    "fid.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from dataset import ZodiacDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 2.3.3 实例化数据集类\n",
    "\n",
    "根据所使用的数据集需求实例化数据集类，并查看总样本量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练数据集：7096张；验证数据集：639张\n"
     ]
    }
   ],
   "source": [
    "train_dataset = ZodiacDataset(mode='train')\n",
    "valid_dataset = ZodiacDataset(mode='valid')\n",
    "\n",
    "print('训练数据集：{}张；验证数据集：{}张'.format(len(train_dataset), len(valid_dataset)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# ③ 模型选择和开发\n",
    "\n",
    "## 3.1 网络构建\n",
    "\n",
    "本次我们使用ResNet50网络来完成我们的案例实践。\n",
    "\n",
    "**1）ResNet系列网络**\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/e671828a87424802844246864a66b8100a54e86662b84e269c8758b89625e39b)\n",
    "\n",
    "**2）ResNet50结构**\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/a9045103588d49b09b35855d347f683af9d1926910ad4b639ccf1ec5c36fb7be)\n",
    "\n",
    "**3）残差区块**\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/b2d06daceb7043a8962ba0bd339129731c1c974233ac4baebb074b912f45f80f)\n",
    "\n",
    "**4）ResNet其他版本**\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/d46a2e84bcae40fe95c638b4eb7252b8b9d2767d1c08497da904c3095aa39abb)\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/53744138423e4395ae26248aa79d2982fde0321d3ccc44f0b2b764aa54363a98)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-22 15:09:17,426 - INFO - unique_endpoints {''}\n",
      "2021-03-22 15:09:17,427 - INFO - Downloading vgg16.pdparams from https://paddle-hapi.bj.bcebos.com/models/vgg16.pdparams\n",
      "100%|██████████| 817517/817517 [00:11<00:00, 68290.64it/s]\n",
      "2021-03-22 15:09:29,570 - INFO - File /home/aistudio/.cache/paddle/hapi/weights/vgg16.pdparams md5 checking...\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dygraph/layers.py:1303: UserWarning: Skip loading for classifier.6.weight. classifier.6.weight receives a shape [4096, 1000], but the expected shape is [4096, 12].\n",
      "  warnings.warn((\"Skip loading for {}. \".format(key) + str(err)))\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dygraph/layers.py:1303: UserWarning: Skip loading for classifier.6.bias. classifier.6.bias receives a shape [1000], but the expected shape is [12].\n",
      "  warnings.warn((\"Skip loading for {}. \".format(key) + str(err)))\n"
     ]
    }
   ],
   "source": [
    "# 请补齐模型实例化代码\n",
    "\n",
    "# network = ?\n",
    "# resnet50\n",
    "# network = paddle.vision.models.resnet50(num_classes=get('num_classes'),pretrained=True)\n",
    "network = paddle.vision.models.vgg16(num_classes=get('num_classes'),pretrained=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**模型可视化**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------\n",
      "   Layer (type)         Input Shape          Output Shape         Param #    \n",
      "===============================================================================\n",
      "     Conv2D-1        [[1, 3, 224, 224]]   [1, 64, 224, 224]        1,792     \n",
      "      ReLU-1        [[1, 64, 224, 224]]   [1, 64, 224, 224]          0       \n",
      "     Conv2D-2       [[1, 64, 224, 224]]   [1, 64, 224, 224]       36,928     \n",
      "      ReLU-2        [[1, 64, 224, 224]]   [1, 64, 224, 224]          0       \n",
      "    MaxPool2D-1     [[1, 64, 224, 224]]   [1, 64, 112, 112]          0       \n",
      "     Conv2D-3       [[1, 64, 112, 112]]   [1, 128, 112, 112]      73,856     \n",
      "      ReLU-3        [[1, 128, 112, 112]]  [1, 128, 112, 112]         0       \n",
      "     Conv2D-4       [[1, 128, 112, 112]]  [1, 128, 112, 112]      147,584    \n",
      "      ReLU-4        [[1, 128, 112, 112]]  [1, 128, 112, 112]         0       \n",
      "    MaxPool2D-2     [[1, 128, 112, 112]]   [1, 128, 56, 56]          0       \n",
      "     Conv2D-5        [[1, 128, 56, 56]]    [1, 256, 56, 56]       295,168    \n",
      "      ReLU-5         [[1, 256, 56, 56]]    [1, 256, 56, 56]          0       \n",
      "     Conv2D-6        [[1, 256, 56, 56]]    [1, 256, 56, 56]       590,080    \n",
      "      ReLU-6         [[1, 256, 56, 56]]    [1, 256, 56, 56]          0       \n",
      "     Conv2D-7        [[1, 256, 56, 56]]    [1, 256, 56, 56]       590,080    \n",
      "      ReLU-7         [[1, 256, 56, 56]]    [1, 256, 56, 56]          0       \n",
      "    MaxPool2D-3      [[1, 256, 56, 56]]    [1, 256, 28, 28]          0       \n",
      "     Conv2D-8        [[1, 256, 28, 28]]    [1, 512, 28, 28]      1,180,160   \n",
      "      ReLU-8         [[1, 512, 28, 28]]    [1, 512, 28, 28]          0       \n",
      "     Conv2D-9        [[1, 512, 28, 28]]    [1, 512, 28, 28]      2,359,808   \n",
      "      ReLU-9         [[1, 512, 28, 28]]    [1, 512, 28, 28]          0       \n",
      "     Conv2D-10       [[1, 512, 28, 28]]    [1, 512, 28, 28]      2,359,808   \n",
      "      ReLU-10        [[1, 512, 28, 28]]    [1, 512, 28, 28]          0       \n",
      "    MaxPool2D-4      [[1, 512, 28, 28]]    [1, 512, 14, 14]          0       \n",
      "     Conv2D-11       [[1, 512, 14, 14]]    [1, 512, 14, 14]      2,359,808   \n",
      "      ReLU-11        [[1, 512, 14, 14]]    [1, 512, 14, 14]          0       \n",
      "     Conv2D-12       [[1, 512, 14, 14]]    [1, 512, 14, 14]      2,359,808   \n",
      "      ReLU-12        [[1, 512, 14, 14]]    [1, 512, 14, 14]          0       \n",
      "     Conv2D-13       [[1, 512, 14, 14]]    [1, 512, 14, 14]      2,359,808   \n",
      "      ReLU-13        [[1, 512, 14, 14]]    [1, 512, 14, 14]          0       \n",
      "    MaxPool2D-5      [[1, 512, 14, 14]]     [1, 512, 7, 7]           0       \n",
      "AdaptiveAvgPool2D-1   [[1, 512, 7, 7]]      [1, 512, 7, 7]           0       \n",
      "     Linear-1           [[1, 25088]]          [1, 4096]         102,764,544  \n",
      "      ReLU-14           [[1, 4096]]           [1, 4096]              0       \n",
      "     Dropout-1          [[1, 4096]]           [1, 4096]              0       \n",
      "     Linear-2           [[1, 4096]]           [1, 4096]         16,781,312   \n",
      "      ReLU-15           [[1, 4096]]           [1, 4096]              0       \n",
      "     Dropout-2          [[1, 4096]]           [1, 4096]              0       \n",
      "     Linear-3           [[1, 4096]]            [1, 12]            49,164     \n",
      "===============================================================================\n",
      "Total params: 134,309,708\n",
      "Trainable params: 134,309,708\n",
      "Non-trainable params: 0\n",
      "-------------------------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 218.77\n",
      "Params size (MB): 512.35\n",
      "Estimated Total Size (MB): 731.70\n",
      "-------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'total_params': 134309708, 'trainable_params': 134309708}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = paddle.Model(network)\n",
    "model.summary((-1, ) + tuple(get('image_shape')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# ④ 模型训练和优化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss value printed in the log is the current step, and the metric is the average value of previous step.\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/layers/utils.py:77: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  return (isinstance(seq, collections.Sequence) and\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 222/222 [==============================] - loss: 2.2994 - acc_top1: 0.1064 - acc_top5: 0.4711 - 758ms/step        \n",
      "save checkpoint at /home/aistudio/chk_points/0\n",
      "Eval begin...\n",
      "The loss value printed in the log is the current batch, and the metric is the average value of previous step.\n",
      "step 20/20 [==============================] - loss: 1.8183 - acc_top1: 0.1471 - acc_top5: 0.5634 - 806ms/step         \n",
      "Eval samples: 639\n",
      "Epoch 2/20\n",
      "step 222/222 [==============================] - loss: 1.5113 - acc_top1: 0.2129 - acc_top5: 0.6554 - 754ms/step        \n",
      "save checkpoint at /home/aistudio/chk_points/1\n",
      "Eval begin...\n",
      "The loss value printed in the log is the current batch, and the metric is the average value of previous step.\n",
      "step 20/20 [==============================] - loss: 2.2229 - acc_top1: 0.4507 - acc_top5: 0.8623 - 803ms/step         \n",
      "Eval samples: 639\n",
      "Epoch 3/20\n",
      "step 222/222 [==============================] - loss: 1.0639 - acc_top1: 0.4735 - acc_top5: 0.8595 - 760ms/step        \n",
      "save checkpoint at /home/aistudio/chk_points/2\n",
      "Eval begin...\n",
      "The loss value printed in the log is the current batch, and the metric is the average value of previous step.\n",
      "step 20/20 [==============================] - loss: 1.0847 - acc_top1: 0.6354 - acc_top5: 0.9374 - 807ms/step         \n",
      "Eval samples: 639\n",
      "Epoch 4/20\n",
      "step 222/222 [==============================] - loss: 1.4927 - acc_top1: 0.6511 - acc_top5: 0.9257 - 757ms/step        \n",
      "save checkpoint at /home/aistudio/chk_points/3\n",
      "Eval begin...\n",
      "The loss value printed in the log is the current batch, and the metric is the average value of previous step.\n",
      "step 20/20 [==============================] - loss: 0.7057 - acc_top1: 0.7809 - acc_top5: 0.9734 - 808ms/step         \n",
      "Eval samples: 639\n",
      "Epoch 5/20\n",
      "step 222/222 [==============================] - loss: 0.6255 - acc_top1: 0.7351 - acc_top5: 0.9542 - 757ms/step        \n",
      "save checkpoint at /home/aistudio/chk_points/4\n",
      "Eval begin...\n",
      "The loss value printed in the log is the current batch, and the metric is the average value of previous step.\n",
      "step 20/20 [==============================] - loss: 0.2302 - acc_top1: 0.8388 - acc_top5: 0.9844 - 806ms/step         \n",
      "Eval samples: 639\n",
      "Epoch 6/20\n",
      "step 222/222 [==============================] - loss: 0.8921 - acc_top1: 0.7873 - acc_top5: 0.9645 - 755ms/step        \n",
      "save checkpoint at /home/aistudio/chk_points/5\n",
      "Eval begin...\n",
      "The loss value printed in the log is the current batch, and the metric is the average value of previous step.\n",
      "step 20/20 [==============================] - loss: 0.1104 - acc_top1: 0.8513 - acc_top5: 0.9844 - 809ms/step         \n",
      "Eval samples: 639\n",
      "Epoch 7/20\n",
      "step 222/222 [==============================] - loss: 0.3022 - acc_top1: 0.8017 - acc_top5: 0.9687 - 759ms/step        \n",
      "save checkpoint at /home/aistudio/chk_points/6\n",
      "Eval begin...\n",
      "The loss value printed in the log is the current batch, and the metric is the average value of previous step.\n",
      "step 20/20 [==============================] - loss: 0.6542 - acc_top1: 0.8701 - acc_top5: 0.9922 - 807ms/step         \n",
      "Eval samples: 639\n",
      "Epoch 8/20\n",
      "step 222/222 [==============================] - loss: 0.4257 - acc_top1: 0.8350 - acc_top5: 0.9760 - 756ms/step        \n",
      "save checkpoint at /home/aistudio/chk_points/7\n",
      "Eval begin...\n",
      "The loss value printed in the log is the current batch, and the metric is the average value of previous step.\n",
      "step 20/20 [==============================] - loss: 0.6435 - acc_top1: 0.9045 - acc_top5: 0.9890 - 807ms/step         \n",
      "Eval samples: 639\n",
      "Epoch 9/20\n",
      "step 222/222 [==============================] - loss: 0.5998 - acc_top1: 0.8413 - acc_top5: 0.9744 - 757ms/step        \n",
      "save checkpoint at /home/aistudio/chk_points/8\n",
      "Eval begin...\n",
      "The loss value printed in the log is the current batch, and the metric is the average value of previous step.\n",
      "step 20/20 [==============================] - loss: 0.1068 - acc_top1: 0.9124 - acc_top5: 0.9953 - 807ms/step         \n",
      "Eval samples: 639\n",
      "Epoch 10/20\n",
      "step 222/222 [==============================] - loss: 0.4297 - acc_top1: 0.8585 - acc_top5: 0.9794 - 756ms/step        \n",
      "save checkpoint at /home/aistudio/chk_points/9\n",
      "Eval begin...\n",
      "The loss value printed in the log is the current batch, and the metric is the average value of previous step.\n",
      "step 20/20 [==============================] - loss: 0.3923 - acc_top1: 0.9092 - acc_top5: 0.9984 - 814ms/step         \n",
      "Eval samples: 639\n",
      "Epoch 11/20\n",
      "step 222/222 [==============================] - loss: 0.3012 - acc_top1: 0.8757 - acc_top5: 0.9827 - 755ms/step        \n",
      "save checkpoint at /home/aistudio/chk_points/10\n",
      "Eval begin...\n",
      "The loss value printed in the log is the current batch, and the metric is the average value of previous step.\n",
      "step 20/20 [==============================] - loss: 0.3124 - acc_top1: 0.9358 - acc_top5: 0.9906 - 809ms/step         \n",
      "Eval samples: 639\n",
      "Epoch 12/20\n",
      "step 222/222 [==============================] - loss: 0.2921 - acc_top1: 0.8842 - acc_top5: 0.9860 - 758ms/step        \n",
      "save checkpoint at /home/aistudio/chk_points/11\n",
      "Eval begin...\n",
      "The loss value printed in the log is the current batch, and the metric is the average value of previous step.\n",
      "step 20/20 [==============================] - loss: 0.2962 - acc_top1: 0.9155 - acc_top5: 0.9906 - 806ms/step         \n",
      "Eval samples: 639\n",
      "Epoch 13/20\n",
      "step 222/222 [==============================] - loss: 0.5272 - acc_top1: 0.8946 - acc_top5: 0.9877 - 759ms/step        \n",
      "save checkpoint at /home/aistudio/chk_points/12\n",
      "Eval begin...\n",
      "The loss value printed in the log is the current batch, and the metric is the average value of previous step.\n",
      "step 20/20 [==============================] - loss: 0.6094 - acc_top1: 0.9171 - acc_top5: 0.9969 - 810ms/step         \n",
      "Eval samples: 639\n",
      "Epoch 14/20\n",
      "step 222/222 [==============================] - loss: 0.3111 - acc_top1: 0.9021 - acc_top5: 0.9859 - 760ms/step        \n",
      "save checkpoint at /home/aistudio/chk_points/13\n",
      "Eval begin...\n",
      "The loss value printed in the log is the current batch, and the metric is the average value of previous step.\n",
      "step 20/20 [==============================] - loss: 0.7377 - acc_top1: 0.9264 - acc_top5: 0.9937 - 806ms/step         \n",
      "Eval samples: 639\n",
      "Epoch 15/20\n",
      "step 222/222 [==============================] - loss: 0.1931 - acc_top1: 0.9111 - acc_top5: 0.9887 - 757ms/step        \n",
      "save checkpoint at /home/aistudio/chk_points/14\n",
      "Eval begin...\n",
      "The loss value printed in the log is the current batch, and the metric is the average value of previous step.\n",
      "step 20/20 [==============================] - loss: 0.4623 - acc_top1: 0.9311 - acc_top5: 0.9937 - 804ms/step         \n",
      "Eval samples: 639\n",
      "Epoch 16/20\n",
      "step 222/222 [==============================] - loss: 0.3006 - acc_top1: 0.9176 - acc_top5: 0.9887 - 756ms/step        \n",
      "save checkpoint at /home/aistudio/chk_points/15\n",
      "Eval begin...\n",
      "The loss value printed in the log is the current batch, and the metric is the average value of previous step.\n",
      "step 20/20 [==============================] - loss: 0.3357 - acc_top1: 0.9311 - acc_top5: 0.9984 - 810ms/step         \n",
      "Eval samples: 639\n",
      "Epoch 17/20\n",
      "step 222/222 [==============================] - loss: 0.1240 - acc_top1: 0.9262 - acc_top5: 0.9891 - 755ms/step        \n",
      "save checkpoint at /home/aistudio/chk_points/16\n",
      "Eval begin...\n",
      "The loss value printed in the log is the current batch, and the metric is the average value of previous step.\n",
      "step 20/20 [==============================] - loss: 0.4157 - acc_top1: 0.9343 - acc_top5: 0.9969 - 812ms/step         \n",
      "Eval samples: 639\n",
      "Epoch 18/20\n",
      "step 222/222 [==============================] - loss: 0.4572 - acc_top1: 0.9212 - acc_top5: 0.9893 - 756ms/step        \n",
      "save checkpoint at /home/aistudio/chk_points/17\n",
      "Eval begin...\n",
      "The loss value printed in the log is the current batch, and the metric is the average value of previous step.\n",
      "step 20/20 [==============================] - loss: 0.7409 - acc_top1: 0.9327 - acc_top5: 0.9953 - 808ms/step         \n",
      "Eval samples: 639\n",
      "Epoch 19/20\n",
      "step 222/222 [==============================] - loss: 0.1562 - acc_top1: 0.9295 - acc_top5: 0.9883 - 760ms/step        \n",
      "save checkpoint at /home/aistudio/chk_points/18\n",
      "Eval begin...\n",
      "The loss value printed in the log is the current batch, and the metric is the average value of previous step.\n",
      "step 20/20 [==============================] - loss: 0.1722 - acc_top1: 0.9405 - acc_top5: 0.9984 - 808ms/step         \n",
      "Eval samples: 639\n",
      "Epoch 20/20\n",
      "step 222/222 [==============================] - loss: 0.1263 - acc_top1: 0.9238 - acc_top5: 0.9879 - 759ms/step        \n",
      "save checkpoint at /home/aistudio/chk_points/19\n",
      "Eval begin...\n",
      "The loss value printed in the log is the current batch, and the metric is the average value of previous step.\n",
      "step 20/20 [==============================] - loss: 0.4926 - acc_top1: 0.9280 - acc_top5: 0.9953 - 809ms/step         \n",
      "Eval samples: 639\n",
      "save checkpoint at /home/aistudio/chk_points/final\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = get('epochs')\n",
    "BATCH_SIZE = get('batch_size')\n",
    "\n",
    "# 请补齐模型训练过程代码\n",
    "def create_optim(parameters):\n",
    "    step_each_epoch = get('total_images')//get('batch_size')\n",
    "    lr = paddle.optimizer.lr.CosineAnnealingDecay(learning_rate=get('LEARNING_RATE.params.lr'),\n",
    "                                                    T_max=step_each_epoch*EPOCHS)\n",
    "\n",
    "    return paddle.optimizer.Momentum(learning_rate=lr,\n",
    "                                        parameters=parameters,\n",
    "                                        weight_decay=paddle.regularizer.L2Decay(get('OPTIMIZER.regularizer.factor')))\n",
    "\n",
    "# 模型训练配置\n",
    "model.prepare(create_optim(network.parameters()),\n",
    "                paddle.nn.CrossEntropyLoss(),\n",
    "                paddle.metric.Accuracy(topk=(1,5)))\n",
    "\n",
    "# 可视化工具VisualDL的回调函数\n",
    "visualdl = paddle.callbacks.VisualDL(log_dir='visualdl_log')\n",
    "\n",
    "# 启动模型训练\n",
    "model.fit(train_dataset,\n",
    "          valid_dataset,\n",
    "          epochs=EPOCHS,\n",
    "          batch_size=BATCH_SIZE,\n",
    "          shuffle=True,\n",
    "          verbose=1,\n",
    "          save_dir='./chk_points/',\n",
    "          callbacks=[visualdl])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 模型存储\n",
    "\n",
    "将我们训练得到的模型进行保存，以便后续评估和测试使用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.save(get('model_save_dir'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# ⑤ 模型评估和测试"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 5.1 批量预测测试\n",
    "\n",
    "### 5.1.1 测试数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "测试数据集样本量：646\n"
     ]
    }
   ],
   "source": [
    "predict_dataset = ZodiacDataset(mode='test')\n",
    "print('测试数据集样本量：{}'.format(len(predict_dataset)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 5.1.2 执行预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict begin...\n",
      "step 646/646 [==============================] - 24ms/step         \n",
      "Predict samples: 646\n"
     ]
    }
   ],
   "source": [
    "from paddle.static import InputSpec\n",
    "\n",
    "# 请补充网络结构\n",
    "\n",
    "# 模型结构\n",
    "# network = paddle.vision.models.resnet50(num_classes=get('num_classes'))\n",
    "network = paddle.vision.models.vgg16(num_classes=get('num_classes'))\n",
    "\n",
    "# 模型封装\n",
    "model_2 = paddle.Model(network, inputs=[InputSpec(shape=[-1] + get('image_shape'), dtype='float32', name='image')])\n",
    "\n",
    "# 请补充模型文件加载代码\n",
    "# 训练好的模型加载\n",
    "model_2.load(get('model_save_dir'))\n",
    "\n",
    "# 模型配置\n",
    "model_2.prepare()\n",
    "\n",
    "# 执行预测\n",
    "result = model_2.predict(predict_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "样本ID：2, 真实标签：pig, 预测值：pig\n",
      "样本ID：38, 真实标签：pig, 预测值：pig\n",
      "样本ID：56, 真实标签：dragon, 预测值：dragon\n",
      "样本ID：92, 真实标签：dragon, 预测值：dragon\n",
      "样本ID：100, 真实标签：dragon, 预测值：dragon\n",
      "样本ID：303, 真实标签：ratt, 预测值：ratt\n"
     ]
    }
   ],
   "source": [
    "# 样本映射\n",
    "LABEL_MAP = get('LABEL_MAP')\n",
    "\n",
    "# 随机取样本展示\n",
    "indexs = [2, 38, 56, 92, 100, 303]\n",
    "\n",
    "for idx in indexs:\n",
    "    predict_label = np.argmax(result[0][idx])\n",
    "    real_label = predict_dataset[idx][1]\n",
    "\n",
    "    print('样本ID：{}, 真实标签：{}, 预测值：{}'.format(idx, LABEL_MAP[real_label], LABEL_MAP[predict_label]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# ⑥ 模型部署"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 可以可视化软件infer/zodiac.pdmodel查看模型结构\r\n",
    "model_2.save('infer/zodiac', training=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PaddlePaddle 2.0.0b0 (Python 3.5)",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
